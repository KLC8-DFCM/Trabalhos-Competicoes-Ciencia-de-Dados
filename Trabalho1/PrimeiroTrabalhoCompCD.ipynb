{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PrimeiroTrabalhoCompCD.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxqDKtYouwN4"
      },
      "source": [
        "#Primeiro trabalho prático\n",
        "##Nome: Diego Fleury Corrêa de Moraes\n",
        "##nusp: 11800584\n",
        "###data: 20/10/2021"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOq9xo5zvWDq",
        "outputId": "f2481291-f1fe-444a-cbc8-91e9fd8cd4d5"
      },
      "source": [
        "# Setup inicial (mais geral)\n",
        "\n",
        "#imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#Configuração para usar a base de dados de modo\n",
        "#eficiente no google colab  --> comentar quando for rodar\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "PROJECT_PATH = '/content/drive/MyDrive/Competicao_DS_Arquivos'\n",
        "\n",
        "!unzip $PROJECT_PATH/house-prices-advanced-regression-techniques.zip\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Archive:  /content/drive/MyDrive/Competicao_DS_Arquivos/house-prices-advanced-regression-techniques.zip\n",
            "replace data_description.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace sample_submission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace test.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKMdwe96wSrV",
        "outputId": "1e476fed-707c-4247-affe-2a03520eee32"
      },
      "source": [
        " !ls "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data_description.txt  sample_data\t     sub.csv   train.csv\n",
            "drive\t\t      sample_submission.csv  test.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4EHW0vRt5aB"
      },
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "\n",
        "target_col = 'SalePrice'\n",
        "\n",
        "y = pd.DataFrame(train[target_col])\n",
        "X = train.drop(target_col,axis=1)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DlpIyV9vnyt"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    train_size=0.65,\n",
        "    random_state=42\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzAdoNVmzjTk"
      },
      "source": [
        "Primeiramente, analiza-se a descrição de todas as features disponíveis. A partir disso será possível notarmos alguns padrões."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wXqxrYszm-P",
        "outputId": "533b903d-ffa0-467f-af92-5805303c37d0"
      },
      "source": [
        "!cat data_description.txt"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSSubClass: Identifies the type of dwelling involved in the sale.\t\n",
            "\n",
            "        20\t1-STORY 1946 & NEWER ALL STYLES\n",
            "        30\t1-STORY 1945 & OLDER\n",
            "        40\t1-STORY W/FINISHED ATTIC ALL AGES\n",
            "        45\t1-1/2 STORY - UNFINISHED ALL AGES\n",
            "        50\t1-1/2 STORY FINISHED ALL AGES\n",
            "        60\t2-STORY 1946 & NEWER\n",
            "        70\t2-STORY 1945 & OLDER\n",
            "        75\t2-1/2 STORY ALL AGES\n",
            "        80\tSPLIT OR MULTI-LEVEL\n",
            "        85\tSPLIT FOYER\n",
            "        90\tDUPLEX - ALL STYLES AND AGES\n",
            "       120\t1-STORY PUD (Planned Unit Development) - 1946 & NEWER\n",
            "       150\t1-1/2 STORY PUD - ALL AGES\n",
            "       160\t2-STORY PUD - 1946 & NEWER\n",
            "       180\tPUD - MULTILEVEL - INCL SPLIT LEV/FOYER\n",
            "       190\t2 FAMILY CONVERSION - ALL STYLES AND AGES\n",
            "\n",
            "MSZoning: Identifies the general zoning classification of the sale.\n",
            "\t\t\n",
            "       A\tAgriculture\n",
            "       C\tCommercial\n",
            "       FV\tFloating Village Residential\n",
            "       I\tIndustrial\n",
            "       RH\tResidential High Density\n",
            "       RL\tResidential Low Density\n",
            "       RP\tResidential Low Density Park \n",
            "       RM\tResidential Medium Density\n",
            "\t\n",
            "LotFrontage: Linear feet of street connected to property\n",
            "\n",
            "LotArea: Lot size in square feet\n",
            "\n",
            "Street: Type of road access to property\n",
            "\n",
            "       Grvl\tGravel\t\n",
            "       Pave\tPaved\n",
            "       \t\n",
            "Alley: Type of alley access to property\n",
            "\n",
            "       Grvl\tGravel\n",
            "       Pave\tPaved\n",
            "       NA \tNo alley access\n",
            "\t\t\n",
            "LotShape: General shape of property\n",
            "\n",
            "       Reg\tRegular\t\n",
            "       IR1\tSlightly irregular\n",
            "       IR2\tModerately Irregular\n",
            "       IR3\tIrregular\n",
            "       \n",
            "LandContour: Flatness of the property\n",
            "\n",
            "       Lvl\tNear Flat/Level\t\n",
            "       Bnk\tBanked - Quick and significant rise from street grade to building\n",
            "       HLS\tHillside - Significant slope from side to side\n",
            "       Low\tDepression\n",
            "\t\t\n",
            "Utilities: Type of utilities available\n",
            "\t\t\n",
            "       AllPub\tAll public Utilities (E,G,W,& S)\t\n",
            "       NoSewr\tElectricity, Gas, and Water (Septic Tank)\n",
            "       NoSeWa\tElectricity and Gas Only\n",
            "       ELO\tElectricity only\t\n",
            "\t\n",
            "LotConfig: Lot configuration\n",
            "\n",
            "       Inside\tInside lot\n",
            "       Corner\tCorner lot\n",
            "       CulDSac\tCul-de-sac\n",
            "       FR2\tFrontage on 2 sides of property\n",
            "       FR3\tFrontage on 3 sides of property\n",
            "\t\n",
            "LandSlope: Slope of property\n",
            "\t\t\n",
            "       Gtl\tGentle slope\n",
            "       Mod\tModerate Slope\t\n",
            "       Sev\tSevere Slope\n",
            "\t\n",
            "Neighborhood: Physical locations within Ames city limits\n",
            "\n",
            "       Blmngtn\tBloomington Heights\n",
            "       Blueste\tBluestem\n",
            "       BrDale\tBriardale\n",
            "       BrkSide\tBrookside\n",
            "       ClearCr\tClear Creek\n",
            "       CollgCr\tCollege Creek\n",
            "       Crawfor\tCrawford\n",
            "       Edwards\tEdwards\n",
            "       Gilbert\tGilbert\n",
            "       IDOTRR\tIowa DOT and Rail Road\n",
            "       MeadowV\tMeadow Village\n",
            "       Mitchel\tMitchell\n",
            "       Names\tNorth Ames\n",
            "       NoRidge\tNorthridge\n",
            "       NPkVill\tNorthpark Villa\n",
            "       NridgHt\tNorthridge Heights\n",
            "       NWAmes\tNorthwest Ames\n",
            "       OldTown\tOld Town\n",
            "       SWISU\tSouth & West of Iowa State University\n",
            "       Sawyer\tSawyer\n",
            "       SawyerW\tSawyer West\n",
            "       Somerst\tSomerset\n",
            "       StoneBr\tStone Brook\n",
            "       Timber\tTimberland\n",
            "       Veenker\tVeenker\n",
            "\t\t\t\n",
            "Condition1: Proximity to various conditions\n",
            "\t\n",
            "       Artery\tAdjacent to arterial street\n",
            "       Feedr\tAdjacent to feeder street\t\n",
            "       Norm\tNormal\t\n",
            "       RRNn\tWithin 200' of North-South Railroad\n",
            "       RRAn\tAdjacent to North-South Railroad\n",
            "       PosN\tNear positive off-site feature--park, greenbelt, etc.\n",
            "       PosA\tAdjacent to postive off-site feature\n",
            "       RRNe\tWithin 200' of East-West Railroad\n",
            "       RRAe\tAdjacent to East-West Railroad\n",
            "\t\n",
            "Condition2: Proximity to various conditions (if more than one is present)\n",
            "\t\t\n",
            "       Artery\tAdjacent to arterial street\n",
            "       Feedr\tAdjacent to feeder street\t\n",
            "       Norm\tNormal\t\n",
            "       RRNn\tWithin 200' of North-South Railroad\n",
            "       RRAn\tAdjacent to North-South Railroad\n",
            "       PosN\tNear positive off-site feature--park, greenbelt, etc.\n",
            "       PosA\tAdjacent to postive off-site feature\n",
            "       RRNe\tWithin 200' of East-West Railroad\n",
            "       RRAe\tAdjacent to East-West Railroad\n",
            "\t\n",
            "BldgType: Type of dwelling\n",
            "\t\t\n",
            "       1Fam\tSingle-family Detached\t\n",
            "       2FmCon\tTwo-family Conversion; originally built as one-family dwelling\n",
            "       Duplx\tDuplex\n",
            "       TwnhsE\tTownhouse End Unit\n",
            "       TwnhsI\tTownhouse Inside Unit\n",
            "\t\n",
            "HouseStyle: Style of dwelling\n",
            "\t\n",
            "       1Story\tOne story\n",
            "       1.5Fin\tOne and one-half story: 2nd level finished\n",
            "       1.5Unf\tOne and one-half story: 2nd level unfinished\n",
            "       2Story\tTwo story\n",
            "       2.5Fin\tTwo and one-half story: 2nd level finished\n",
            "       2.5Unf\tTwo and one-half story: 2nd level unfinished\n",
            "       SFoyer\tSplit Foyer\n",
            "       SLvl\tSplit Level\n",
            "\t\n",
            "OverallQual: Rates the overall material and finish of the house\n",
            "\n",
            "       10\tVery Excellent\n",
            "       9\tExcellent\n",
            "       8\tVery Good\n",
            "       7\tGood\n",
            "       6\tAbove Average\n",
            "       5\tAverage\n",
            "       4\tBelow Average\n",
            "       3\tFair\n",
            "       2\tPoor\n",
            "       1\tVery Poor\n",
            "\t\n",
            "OverallCond: Rates the overall condition of the house\n",
            "\n",
            "       10\tVery Excellent\n",
            "       9\tExcellent\n",
            "       8\tVery Good\n",
            "       7\tGood\n",
            "       6\tAbove Average\t\n",
            "       5\tAverage\n",
            "       4\tBelow Average\t\n",
            "       3\tFair\n",
            "       2\tPoor\n",
            "       1\tVery Poor\n",
            "\t\t\n",
            "YearBuilt: Original construction date\n",
            "\n",
            "YearRemodAdd: Remodel date (same as construction date if no remodeling or additions)\n",
            "\n",
            "RoofStyle: Type of roof\n",
            "\n",
            "       Flat\tFlat\n",
            "       Gable\tGable\n",
            "       Gambrel\tGabrel (Barn)\n",
            "       Hip\tHip\n",
            "       Mansard\tMansard\n",
            "       Shed\tShed\n",
            "\t\t\n",
            "RoofMatl: Roof material\n",
            "\n",
            "       ClyTile\tClay or Tile\n",
            "       CompShg\tStandard (Composite) Shingle\n",
            "       Membran\tMembrane\n",
            "       Metal\tMetal\n",
            "       Roll\tRoll\n",
            "       Tar&Grv\tGravel & Tar\n",
            "       WdShake\tWood Shakes\n",
            "       WdShngl\tWood Shingles\n",
            "\t\t\n",
            "Exterior1st: Exterior covering on house\n",
            "\n",
            "       AsbShng\tAsbestos Shingles\n",
            "       AsphShn\tAsphalt Shingles\n",
            "       BrkComm\tBrick Common\n",
            "       BrkFace\tBrick Face\n",
            "       CBlock\tCinder Block\n",
            "       CemntBd\tCement Board\n",
            "       HdBoard\tHard Board\n",
            "       ImStucc\tImitation Stucco\n",
            "       MetalSd\tMetal Siding\n",
            "       Other\tOther\n",
            "       Plywood\tPlywood\n",
            "       PreCast\tPreCast\t\n",
            "       Stone\tStone\n",
            "       Stucco\tStucco\n",
            "       VinylSd\tVinyl Siding\n",
            "       Wd Sdng\tWood Siding\n",
            "       WdShing\tWood Shingles\n",
            "\t\n",
            "Exterior2nd: Exterior covering on house (if more than one material)\n",
            "\n",
            "       AsbShng\tAsbestos Shingles\n",
            "       AsphShn\tAsphalt Shingles\n",
            "       BrkComm\tBrick Common\n",
            "       BrkFace\tBrick Face\n",
            "       CBlock\tCinder Block\n",
            "       CemntBd\tCement Board\n",
            "       HdBoard\tHard Board\n",
            "       ImStucc\tImitation Stucco\n",
            "       MetalSd\tMetal Siding\n",
            "       Other\tOther\n",
            "       Plywood\tPlywood\n",
            "       PreCast\tPreCast\n",
            "       Stone\tStone\n",
            "       Stucco\tStucco\n",
            "       VinylSd\tVinyl Siding\n",
            "       Wd Sdng\tWood Siding\n",
            "       WdShing\tWood Shingles\n",
            "\t\n",
            "MasVnrType: Masonry veneer type\n",
            "\n",
            "       BrkCmn\tBrick Common\n",
            "       BrkFace\tBrick Face\n",
            "       CBlock\tCinder Block\n",
            "       None\tNone\n",
            "       Stone\tStone\n",
            "\t\n",
            "MasVnrArea: Masonry veneer area in square feet\n",
            "\n",
            "ExterQual: Evaluates the quality of the material on the exterior \n",
            "\t\t\n",
            "       Ex\tExcellent\n",
            "       Gd\tGood\n",
            "       TA\tAverage/Typical\n",
            "       Fa\tFair\n",
            "       Po\tPoor\n",
            "\t\t\n",
            "ExterCond: Evaluates the present condition of the material on the exterior\n",
            "\t\t\n",
            "       Ex\tExcellent\n",
            "       Gd\tGood\n",
            "       TA\tAverage/Typical\n",
            "       Fa\tFair\n",
            "       Po\tPoor\n",
            "\t\t\n",
            "Foundation: Type of foundation\n",
            "\t\t\n",
            "       BrkTil\tBrick & Tile\n",
            "       CBlock\tCinder Block\n",
            "       PConc\tPoured Contrete\t\n",
            "       Slab\tSlab\n",
            "       Stone\tStone\n",
            "       Wood\tWood\n",
            "\t\t\n",
            "BsmtQual: Evaluates the height of the basement\n",
            "\n",
            "       Ex\tExcellent (100+ inches)\t\n",
            "       Gd\tGood (90-99 inches)\n",
            "       TA\tTypical (80-89 inches)\n",
            "       Fa\tFair (70-79 inches)\n",
            "       Po\tPoor (<70 inches\n",
            "       NA\tNo Basement\n",
            "\t\t\n",
            "BsmtCond: Evaluates the general condition of the basement\n",
            "\n",
            "       Ex\tExcellent\n",
            "       Gd\tGood\n",
            "       TA\tTypical - slight dampness allowed\n",
            "       Fa\tFair - dampness or some cracking or settling\n",
            "       Po\tPoor - Severe cracking, settling, or wetness\n",
            "       NA\tNo Basement\n",
            "\t\n",
            "BsmtExposure: Refers to walkout or garden level walls\n",
            "\n",
            "       Gd\tGood Exposure\n",
            "       Av\tAverage Exposure (split levels or foyers typically score average or above)\t\n",
            "       Mn\tMimimum Exposure\n",
            "       No\tNo Exposure\n",
            "       NA\tNo Basement\n",
            "\t\n",
            "BsmtFinType1: Rating of basement finished area\n",
            "\n",
            "       GLQ\tGood Living Quarters\n",
            "       ALQ\tAverage Living Quarters\n",
            "       BLQ\tBelow Average Living Quarters\t\n",
            "       Rec\tAverage Rec Room\n",
            "       LwQ\tLow Quality\n",
            "       Unf\tUnfinshed\n",
            "       NA\tNo Basement\n",
            "\t\t\n",
            "BsmtFinSF1: Type 1 finished square feet\n",
            "\n",
            "BsmtFinType2: Rating of basement finished area (if multiple types)\n",
            "\n",
            "       GLQ\tGood Living Quarters\n",
            "       ALQ\tAverage Living Quarters\n",
            "       BLQ\tBelow Average Living Quarters\t\n",
            "       Rec\tAverage Rec Room\n",
            "       LwQ\tLow Quality\n",
            "       Unf\tUnfinshed\n",
            "       NA\tNo Basement\n",
            "\n",
            "BsmtFinSF2: Type 2 finished square feet\n",
            "\n",
            "BsmtUnfSF: Unfinished square feet of basement area\n",
            "\n",
            "TotalBsmtSF: Total square feet of basement area\n",
            "\n",
            "Heating: Type of heating\n",
            "\t\t\n",
            "       Floor\tFloor Furnace\n",
            "       GasA\tGas forced warm air furnace\n",
            "       GasW\tGas hot water or steam heat\n",
            "       Grav\tGravity furnace\t\n",
            "       OthW\tHot water or steam heat other than gas\n",
            "       Wall\tWall furnace\n",
            "\t\t\n",
            "HeatingQC: Heating quality and condition\n",
            "\n",
            "       Ex\tExcellent\n",
            "       Gd\tGood\n",
            "       TA\tAverage/Typical\n",
            "       Fa\tFair\n",
            "       Po\tPoor\n",
            "\t\t\n",
            "CentralAir: Central air conditioning\n",
            "\n",
            "       N\tNo\n",
            "       Y\tYes\n",
            "\t\t\n",
            "Electrical: Electrical system\n",
            "\n",
            "       SBrkr\tStandard Circuit Breakers & Romex\n",
            "       FuseA\tFuse Box over 60 AMP and all Romex wiring (Average)\t\n",
            "       FuseF\t60 AMP Fuse Box and mostly Romex wiring (Fair)\n",
            "       FuseP\t60 AMP Fuse Box and mostly knob & tube wiring (poor)\n",
            "       Mix\tMixed\n",
            "\t\t\n",
            "1stFlrSF: First Floor square feet\n",
            " \n",
            "2ndFlrSF: Second floor square feet\n",
            "\n",
            "LowQualFinSF: Low quality finished square feet (all floors)\n",
            "\n",
            "GrLivArea: Above grade (ground) living area square feet\n",
            "\n",
            "BsmtFullBath: Basement full bathrooms\n",
            "\n",
            "BsmtHalfBath: Basement half bathrooms\n",
            "\n",
            "FullBath: Full bathrooms above grade\n",
            "\n",
            "HalfBath: Half baths above grade\n",
            "\n",
            "Bedroom: Bedrooms above grade (does NOT include basement bedrooms)\n",
            "\n",
            "Kitchen: Kitchens above grade\n",
            "\n",
            "KitchenQual: Kitchen quality\n",
            "\n",
            "       Ex\tExcellent\n",
            "       Gd\tGood\n",
            "       TA\tTypical/Average\n",
            "       Fa\tFair\n",
            "       Po\tPoor\n",
            "       \t\n",
            "TotRmsAbvGrd: Total rooms above grade (does not include bathrooms)\n",
            "\n",
            "Functional: Home functionality (Assume typical unless deductions are warranted)\n",
            "\n",
            "       Typ\tTypical Functionality\n",
            "       Min1\tMinor Deductions 1\n",
            "       Min2\tMinor Deductions 2\n",
            "       Mod\tModerate Deductions\n",
            "       Maj1\tMajor Deductions 1\n",
            "       Maj2\tMajor Deductions 2\n",
            "       Sev\tSeverely Damaged\n",
            "       Sal\tSalvage only\n",
            "\t\t\n",
            "Fireplaces: Number of fireplaces\n",
            "\n",
            "FireplaceQu: Fireplace quality\n",
            "\n",
            "       Ex\tExcellent - Exceptional Masonry Fireplace\n",
            "       Gd\tGood - Masonry Fireplace in main level\n",
            "       TA\tAverage - Prefabricated Fireplace in main living area or Masonry Fireplace in basement\n",
            "       Fa\tFair - Prefabricated Fireplace in basement\n",
            "       Po\tPoor - Ben Franklin Stove\n",
            "       NA\tNo Fireplace\n",
            "\t\t\n",
            "GarageType: Garage location\n",
            "\t\t\n",
            "       2Types\tMore than one type of garage\n",
            "       Attchd\tAttached to home\n",
            "       Basment\tBasement Garage\n",
            "       BuiltIn\tBuilt-In (Garage part of house - typically has room above garage)\n",
            "       CarPort\tCar Port\n",
            "       Detchd\tDetached from home\n",
            "       NA\tNo Garage\n",
            "\t\t\n",
            "GarageYrBlt: Year garage was built\n",
            "\t\t\n",
            "GarageFinish: Interior finish of the garage\n",
            "\n",
            "       Fin\tFinished\n",
            "       RFn\tRough Finished\t\n",
            "       Unf\tUnfinished\n",
            "       NA\tNo Garage\n",
            "\t\t\n",
            "GarageCars: Size of garage in car capacity\n",
            "\n",
            "GarageArea: Size of garage in square feet\n",
            "\n",
            "GarageQual: Garage quality\n",
            "\n",
            "       Ex\tExcellent\n",
            "       Gd\tGood\n",
            "       TA\tTypical/Average\n",
            "       Fa\tFair\n",
            "       Po\tPoor\n",
            "       NA\tNo Garage\n",
            "\t\t\n",
            "GarageCond: Garage condition\n",
            "\n",
            "       Ex\tExcellent\n",
            "       Gd\tGood\n",
            "       TA\tTypical/Average\n",
            "       Fa\tFair\n",
            "       Po\tPoor\n",
            "       NA\tNo Garage\n",
            "\t\t\n",
            "PavedDrive: Paved driveway\n",
            "\n",
            "       Y\tPaved \n",
            "       P\tPartial Pavement\n",
            "       N\tDirt/Gravel\n",
            "\t\t\n",
            "WoodDeckSF: Wood deck area in square feet\n",
            "\n",
            "OpenPorchSF: Open porch area in square feet\n",
            "\n",
            "EnclosedPorch: Enclosed porch area in square feet\n",
            "\n",
            "3SsnPorch: Three season porch area in square feet\n",
            "\n",
            "ScreenPorch: Screen porch area in square feet\n",
            "\n",
            "PoolArea: Pool area in square feet\n",
            "\n",
            "PoolQC: Pool quality\n",
            "\t\t\n",
            "       Ex\tExcellent\n",
            "       Gd\tGood\n",
            "       TA\tAverage/Typical\n",
            "       Fa\tFair\n",
            "       NA\tNo Pool\n",
            "\t\t\n",
            "Fence: Fence quality\n",
            "\t\t\n",
            "       GdPrv\tGood Privacy\n",
            "       MnPrv\tMinimum Privacy\n",
            "       GdWo\tGood Wood\n",
            "       MnWw\tMinimum Wood/Wire\n",
            "       NA\tNo Fence\n",
            "\t\n",
            "MiscFeature: Miscellaneous feature not covered in other categories\n",
            "\t\t\n",
            "       Elev\tElevator\n",
            "       Gar2\t2nd Garage (if not described in garage section)\n",
            "       Othr\tOther\n",
            "       Shed\tShed (over 100 SF)\n",
            "       TenC\tTennis Court\n",
            "       NA\tNone\n",
            "\t\t\n",
            "MiscVal: $Value of miscellaneous feature\n",
            "\n",
            "MoSold: Month Sold (MM)\n",
            "\n",
            "YrSold: Year Sold (YYYY)\n",
            "\n",
            "SaleType: Type of sale\n",
            "\t\t\n",
            "       WD \tWarranty Deed - Conventional\n",
            "       CWD\tWarranty Deed - Cash\n",
            "       VWD\tWarranty Deed - VA Loan\n",
            "       New\tHome just constructed and sold\n",
            "       COD\tCourt Officer Deed/Estate\n",
            "       Con\tContract 15% Down payment regular terms\n",
            "       ConLw\tContract Low Down payment and low interest\n",
            "       ConLI\tContract Low Interest\n",
            "       ConLD\tContract Low Down\n",
            "       Oth\tOther\n",
            "\t\t\n",
            "SaleCondition: Condition of sale\n",
            "\n",
            "       Normal\tNormal Sale\n",
            "       Abnorml\tAbnormal Sale -  trade, foreclosure, short sale\n",
            "       AdjLand\tAdjoining Land Purchase\n",
            "       Alloca\tAllocation - two linked properties with separate deeds, typically condo with a garage unit\t\n",
            "       Family\tSale between family members\n",
            "       Partial\tHome was not completed when last assessed (associated with New Homes)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2Au44Rfz2P3"
      },
      "source": [
        "#Separação de campos de features\n",
        "À partir de uma análise de todas as features são feitas as seguintes partições dos tipos de grupos em que serão separadas. A escolha de separação leva em conta a noção de que, dadas variáveis próximas em significado (referem-se a um mesmo objeto, ideia ou noção) tem-se alta probabilidade que estão, não somente altamente correlacionadas como também a união destas informações provavelmente é mais útil ao modelo do que cada uma em si.\n",
        "\n",
        "São adicionadas 3 features mais descritivas novas que, embora possam ser colocadas em outros grupos terão um grupo separado para sua análise/agrupamento. Esta decisão é justificada na medida em que possuem características em comum (serem um tamanho médio de alguma grandeza que geralmente resulta em uma maior valorização do imóvel) e para fins de teste de sua qualidade como noções úteis ou não ao modelo.\n",
        "\n",
        "Além disso são descartadas algumas features por não serem úteis do ponto de vista prático, como informações da venda (que não estariam disponíveis em uma aplicação real do modelo) e o id (apenas um metadado)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfSw5oF8GFaR",
        "outputId": "03fa71aa-71b9-4914-d013-2a4cee24f2d9"
      },
      "source": [
        "#como, para este dataset, não temos valores nulos de área, e é uma feature \n",
        "#que dificilmente do ponto de vista prático estaria em falta, \n",
        "#descarta-se a necessidade de correção de valores nulos\n",
        "\n",
        "X_train['LotArea'].isna().sum(), X_test['LotArea'].isna().sum()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 0)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdJSmac-8tKI"
      },
      "source": [
        "##Questão 1\n",
        "\n",
        "###a) Proponha 3 novas variáveis explicativas que façam sentido do ponto de vista prático do problema;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUTHu4gsDDL3"
      },
      "source": [
        "#Criacao de features novas\n",
        "#train\n",
        "total_area_train = X_train['LotArea'] + X_train['1stFlrSF'] + X_train['2ndFlrSF']\n",
        "X_train['AvgAbvGrLivArea'] = X_train['GrLivArea']/total_area_train\n",
        "X_train['AvgRmsAbvGrdSize'] = X_train['TotRmsAbvGrd']/total_area_train\n",
        "X_train['AvgBedroomAbvGrSize'] = X_train['BedroomAbvGr']/total_area_train\n",
        "\n",
        "#test\n",
        "total_area_test = X_test['LotArea'] + X_test['1stFlrSF'] + X_test['2ndFlrSF']\n",
        "X_test['AvgAbvGrLivArea'] = X_test['GrLivArea']/total_area_test\n",
        "X_test['AvgRmsAbvGrdSize'] = X_test['TotRmsAbvGrd']/total_area_test\n",
        "X_test['AvgBedroomAbvGrSize'] = X_test['BedroomAbvGr']/total_area_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kjj0nNbs9NKS"
      },
      "source": [
        "#Questão 2\n",
        "###b) Faça uso de uma técnica de modelagem ainda não falada na disciplina. \n",
        "Essa técnica não precisa ser uma modelo de regressão, ela pode ser uma técnica\n",
        "de agrupamento para ajudar na criação de novas variáveis. Considere como\n",
        "técnicas já vistas: **KNN, árvores e ensembles**.\n",
        "\n",
        "* (Usada KMeans para agrupamento de noções similares, sob a hipótese de alta correlação entre elas)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6P5JcCQG2IF"
      },
      "source": [
        "#features novas agrupadas: 3\n",
        "avgs = [\n",
        "        'AvgAbvGrLivArea', 'AvgRmsAbvGrdSize', 'AvgBedroomAbvGrSize'\n",
        "]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6F8QG76BKcP2"
      },
      "source": [
        "#features pouco (ou não) relevantes ao problema: -5\n",
        "drop = [\n",
        "'Id', 'MoSold', 'YrSold','SaleType',\n",
        "'SaleCondition'    \n",
        "]\n",
        "\n",
        "#features relacionadas à garagem: 8\n",
        "garage = [\"GarageType\",'GarageYrBlt', 'GarageFinish',\n",
        "        'GarageCars', 'GarageArea', 'GarageQual', 'GarageCond','PavedDrive'\n",
        "]\n",
        "\n",
        "#features relacionadas ao porão: 11\n",
        "bsmt = ['BsmtQual', 'BsmtCond',\n",
        "        'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2',\n",
        "        'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF',\n",
        "            'BsmtFullBath', 'BsmtHalfBath'\n",
        "]\n",
        "\n",
        "#features relacinadas a valores considerados (de certa forma) \"de luxo\": 12\n",
        "extras = ['WoodDeckSF','OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch',\n",
        "          'PoolArea', 'PoolQC', 'Fence',\n",
        "        'MiscFeature', 'MiscVal','Fireplaces','FireplaceQu'\n",
        "]\n",
        "\n",
        "#features relacionadas a localizacao: 6\n",
        "local = ['MSZoning','Alley','Street',\n",
        "         'Neighborhood', 'Condition1','Condition2'\n",
        "]\n",
        "\n",
        "#features relacionadas a infraestrutura da casa em geral: 14\n",
        "infra = ['Utilities','OverallQual', 'OverallCond','YearBuilt','YearRemodAdd',\n",
        "            'ExterQual', 'ExterCond', 'Foundation',\n",
        "                  'Heating', 'HeatingQC','CentralAir', 'Electrical',\n",
        "         'LowQualFinSF','Functional'\n",
        "]\n",
        "\n",
        "#features relacionadas ao terreno e estilo da casa em si : 18\n",
        "terreno_estilo= ['MSSubClass', 'LotFrontage', 'LotArea',\n",
        "                    'LotShape', 'LandContour', 'LotConfig','LandSlope',\n",
        "                    'BldgType', 'HouseStyle','YearBuilt', 'YearRemodAdd', \n",
        "                     'Exterior1st', 'Exterior2nd',\n",
        "                     'MasVnrType', 'MasVnrArea','1stFlrSF', '2ndFlrSF',\n",
        "                    'GrLivArea'\n",
        "]\n",
        "\n",
        "#features relacionadas a banheiros: 2\n",
        "bathroom = [\n",
        "      'FullBath','HalfBath'\n",
        "]\n",
        "\n",
        "#features relacionadas a quartos: 2\n",
        "bedroom = [\n",
        "   'TotRmsAbvGrd', 'BedroomAbvGr'\n",
        "]\n",
        "\n",
        "#features relacionadas a cozinha: 2\n",
        "kitchen = [\n",
        "    'KitchenQual','KitchenAbvGr'\n",
        "]\n",
        "\n",
        "#features relacionadas ao telhado: 2\n",
        "roof = [\n",
        "    'RoofMatl', 'RoofStyle'\n",
        "]\n",
        "\n",
        "grupos = [garage,bsmt,extras,local,\n",
        "          infra,terreno_estilo,bathroom,\n",
        "          bedroom,kitchen,roof,avgs]\n",
        "\n",
        "grupos_nomes = ['garage','bsmt','extras','local',\n",
        "          'infra','terreno_estilo','bathroom',\n",
        "          'bedroom','kitchen','roof','avgs']"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dry7G_H2IjiA"
      },
      "source": [
        "#Criação de features novas\n",
        "Inicialmente, temos de fazer a separação de variáveis numéricas e categóricas. \n",
        "Embora isto possa ser feito de outra maneira, após uma investigação mais a fundo, o procedimento não é tão simples quanto apenas separar em dtypes numéricos e categóricos, pois temos situações em que valores numéricos na verdade, quando vistos pela descrição, são categóricos, enquanto alguns valores categóricos são na verdade ordinais, os quais correspondem a uma noção numérica. \n",
        "Exemplos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iden57Bq3RAH",
        "outputId": "51d3651f-1ed5-4ec0-f49f-2d4f36d4f1a8"
      },
      "source": [
        "#esta feature apenas identifica o \"tipo de habitação envolvida na venda\", porém possui uma codificação por números inteiros\n",
        "print(X_train['MSSubClass'].dtypes)\n",
        "\n",
        "#esta feature é categórica porém indica em sua descrição um nível de regularidade do terreno, sendo no fundo uma noção ordinal, que é inerentemente numérica\n",
        "print(X_train['LotShape'].dtypes)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "int64\n",
            "object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyePc83MWg9s"
      },
      "source": [
        "Para isto, são criadas algumas funções para este processamento. O tratamento matemático escolhido é o agrupamento das features numéricas de modo que estejam **normais** (StandardScaler), um simples tratamento **esparso** na forma de OneHotEncoding para as features puramente categóricas e, enfim, a tentativa de captura uma noção de **ordem relativa** à máxima (100% = 1) nas features ordinais, sendo inicialmente feita a codificação da ordem encontrada (OrdinalEncoder) e, enfim, a mudança de escala para unitária.\n",
        "\n",
        "As funções implementadas para este fim estão mostradas logo abaixo:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEFMK0buHx_f"
      },
      "source": [
        "#Importação de bibliotecas úteis ao problema"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvvjjQuzASUk"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder,StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.impute import SimpleImputer"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSuxATKDmSvI"
      },
      "source": [
        "Imputamento de valores é feito através de chamada a uma função separada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpF9FPWQ6YL_"
      },
      "source": [
        "def imputa_valores(df_grupo,feat_num,feat_cat,feat_ord):\n",
        "\n",
        "    if(len(feat_num)!=0):\n",
        "      #tratamento de valores numericos\n",
        "      imp_mean = SimpleImputer(missing_values=np.NaN, strategy='mean')\n",
        "      df_grupo[feat_num] = imp_mean.fit_transform(df_grupo[feat_num])\n",
        "    \n",
        "    if(len(feat_cat)!=0):\n",
        "      #tratamento de valores categoricos\n",
        "      df_grupo[feat_cat] = df_grupo[feat_cat].fillna('Unk')\n",
        "    \n",
        "    if(len(feat_ord)!=0):\n",
        "      #tratamento de valores ordinais\n",
        "      imp_mode = SimpleImputer(missing_values=np.NaN,strategy='most_frequent')\n",
        "      df_grupo[feat_ord] =  imp_mode.fit_transform(df_grupo[feat_ord])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrMC2692H2tf"
      },
      "source": [
        "#Função responsável pelo 'fit' do agrupamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TDzufx4CrnI"
      },
      "source": [
        "def agrupamento_fit(df_grupo,feat_num,feat_cat,feat_ord,ordem):\n",
        "  '''\n",
        "  Esta funcao realiza o agrupamento proposto para o preprocessamento\n",
        "  dos dados, fazendo a distincao entre variaveis numericas, categoricas\n",
        "  e ordinais, de forma que dados:\n",
        "\n",
        "  *Numericos sao normalizados\n",
        "\n",
        "  *Categoricos sao codificados em OneHotEncoder\n",
        "\n",
        "  *Ordinais sao codificados em OrdinalEncoder\n",
        "\n",
        "  '''  \n",
        "\n",
        "  #Imputamento\n",
        "  imputa_valores(df_grupo,feat_num,feat_cat,feat_ord)\n",
        "\n",
        "  if(len(feat_num)!=0):\n",
        "\n",
        "    #tratamento numerico dado\n",
        "    ss_grupo = StandardScaler()\n",
        "    ss_grupo.fit(df_grupo[feat_num])\n",
        "\n",
        "  else:\n",
        "    ss_grupo = False\n",
        "\n",
        "  if(len(feat_cat)!=0):\n",
        "\n",
        "    #tratamento numerico dado\n",
        "    ohe_grupo = OneHotEncoder(sparse=False,handle_unknown='ignore')\n",
        "    ohe_grupo.fit(df_grupo[feat_cat])\n",
        "\n",
        "  else:\n",
        "    ohe_grupo = False\n",
        "\n",
        "  if(len(feat_ord)!=0):\n",
        "\n",
        "    #tratamento numerico dado\n",
        "    oe_grupo = OrdinalEncoder(categories=ordem)\n",
        "    oe_grupo.fit(df_grupo[feat_ord])\n",
        "\n",
        "  else:\n",
        "    oe_grupo = False\n",
        "\n",
        "  return (ss_grupo,ohe_grupo,oe_grupo)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXqiGqMNH-VJ"
      },
      "source": [
        "#Função responsável pelo 'transform' do agrupamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XPl1yYYCsto"
      },
      "source": [
        "def agrupamento_transform(df_grupo, feat_num, feat_cat, feat_ord, max_ord,\n",
        "                          ss_grupo, ohe_grupo, oe_grupo):\n",
        "  '''\n",
        "  Esta funcao recebe os estimators obtidos em agrupamento fit e transforma os valores baseados\n",
        "  na operação desejada, ao final retornando os tres tipos concatenados\n",
        "  '''\n",
        "\n",
        "  #criar variavel de saida boba, como uma coluna de zeros que sera\n",
        "  #dropada ao final\n",
        "\n",
        "  imputa_valores(df_grupo,feat_num,feat_cat,feat_ord)\n",
        "\n",
        "  #pequeno truque introduzido para condicionalmente poder agregar valores\n",
        "  feat_grupo = np.zeros((len(df_grupo),1))\n",
        "\n",
        "  if(ss_grupo != False):\n",
        "    num_grupo = ss_grupo.transform(df_grupo[feat_num])\n",
        "    feat_grupo = np.append(feat_grupo,num_grupo, axis=1)\n",
        "\n",
        "  if(ohe_grupo != False):\n",
        "    cat_grupo = ohe_grupo.transform(df_grupo[feat_cat])\n",
        "    feat_grupo = np.append(feat_grupo,cat_grupo, axis=1)\n",
        "\n",
        "  #max_ord é um vetor dos maiores valores por coluna (ou seja, por feature\n",
        "  #ordinal). Efetuada a divisão desta forma, um vetor do tipo [[1,1],[2,2]]\n",
        "  #\"dividido\" por um vetor do tipo [1,2] resulta em [[1,1],[1,1]]\n",
        "  if(oe_grupo != False):\n",
        "    ord_grupo = oe_grupo.transform(df_grupo[feat_ord]) / max_ord\n",
        "    feat_grupo = np.append(feat_grupo,ord_grupo, axis=1)\n",
        "\n",
        "  #ao final dar drop na 1a coluna do numpy array (boba)\n",
        "  feat_grupo = np.delete(feat_grupo, 0, 1)\n",
        "\n",
        "  return feat_grupo"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3sEzYwgKCZL"
      },
      "source": [
        "Nota: a escolha de alcance entre 0 e 1 para categóricas (puras ou ordinais) e com *possibilidade* de extrapolação de escala para numéricas fora feita de forma para que, em média, as features estejam entre 0 e 1 (pois isso é útil para KMeans) porém em casos que possuem outliers numéricos essas relações sejam mais realçadas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lvo3rzrIEUg"
      },
      "source": [
        "#Função responsável pela criação 'fit' das novas features agrupadas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2uQB17FoKq5"
      },
      "source": [
        "* Nota: para fins de futura análise, o valor de k também é retornado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caCjCPIeC2SM"
      },
      "source": [
        "def kmeans_features_fit(feat_grupo,k_max=10):\n",
        "  '''\n",
        "  Esta funcao recebe os valores retornados por agrupamento_transform e\n",
        "  realiza a transformacao, retornando o melhor \"agrupador\" KMean de features\n",
        "  '''\n",
        "\n",
        "  silhoutte_list = []\n",
        "  for k in range(2,k_max+1):\n",
        "    kmean = KMeans(n_clusters=k)\n",
        "    kmean.fit(feat_grupo)\n",
        "    silhoutte_list.append(silhouette_score(feat_grupo, kmean.labels_))\n",
        "\n",
        "  silhoutte_list = np.array(silhoutte_list)\n",
        "  k_melhor = 2 + np.argmax(silhoutte_list)\n",
        "  print(\"=======================================\")\n",
        "  print(\"======= Melhor k = \",k_melhor,\" =======\")\n",
        "  print(\"=======================================\")\n",
        "\n",
        "  Kmean_Final = KMeans(n_clusters=k_melhor)\n",
        "  Kmean_Final.fit(feat_grupo)\n",
        "  return (Kmean_Final,k_melhor)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnA4i05vIM-i"
      },
      "source": [
        "#Função responsável pelo 'transform' das novas features agrupadas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8hg6cU6C3BO"
      },
      "source": [
        "def k_means_features_transform(KMean_Final,feat_grupo):\n",
        "  '''\n",
        "  Esta funcao retorna, finalmente, os valores finais das\n",
        "  features do grupo\n",
        "  '''\n",
        "  final_group_feat = KMean_Final.transform(feat_grupo)\n",
        "  return final_group_feat"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Arbhw8pQIVN8"
      },
      "source": [
        "##Esta função tem como objetivo retornar os valores máximos dentro de uma **ORDEM** estabelecida. Isso ocorre pois estamos tentando normalizar a escala das features ordinais entre 0 e 1 com relação à **todos** os valores possíveis, descritos em data_description.txt, não apenas os mínimos e máximos presentes em tempo de treino (por isso não se utiliza MinMaxScaler)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uk5Z14GRBqqc"
      },
      "source": [
        "def array_de_normalizacao_das_ordinais(ordem):\n",
        "  lenghts = []\n",
        "  for ordenacao in ordem:\n",
        "    lenghts.append(len(ordenacao))\n",
        "  return (np.array(lenghts))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idLefNnEK4x9"
      },
      "source": [
        "Para facilitar a aplicação das funções anteriores, foram criadas as seguintes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ei-mrfZBC671"
      },
      "source": [
        "def features_abstraidas_por_grupo_fit_transform(df_grupo,feat_num,feat_cat,feat_ord,ordem,k_max=10):\n",
        "\n",
        "  ss_grupo, ohe_grupo, oe_grupo = agrupamento_fit(df_grupo,feat_num,feat_cat,feat_ord,ordem)\n",
        "\n",
        "  feat_grupo= agrupamento_transform(df_grupo,feat_num,feat_cat,feat_ord,array_de_normalizacao_das_ordinais(ordem), ss_grupo,ohe_grupo,oe_grupo)\n",
        "\n",
        "  KMeanModeloGrupo , k_melhor_grupo = kmeans_features_fit(feat_grupo,k_max)\n",
        "\n",
        "  final_grupo_feat = k_means_features_transform(KMeanModeloGrupo,feat_grupo)\n",
        "\n",
        "  return (final_grupo_feat, (ss_grupo, ohe_grupo, oe_grupo, KMeanModeloGrupo), k_melhor_grupo )\n",
        "\n",
        "def features_abstraidas_por_grupo_transform(df_grupo,feat_num,feat_cat,feat_ord,ordem,ss_grupo, ohe_grupo, oe_grupo, KMeanModeloGrupo):\n",
        "\n",
        "  feat_grupo = agrupamento_transform(df_grupo,feat_num,feat_cat,feat_ord,array_de_normalizacao_das_ordinais(ordem), ss_grupo,ohe_grupo,oe_grupo)\n",
        "\n",
        "  final_grupo_feat = k_means_features_transform(KMeanModeloGrupo,feat_grupo)\n",
        "\n",
        "  return final_grupo_feat"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwmUxo7TLG8K"
      },
      "source": [
        "###Para a realização, de forma mais modular, das transformações necessárias, foram utilizados os seguintes dicionários/mapeamentos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0nHLj0H4R7t"
      },
      "source": [
        "#Descrição de todas as features numéricas em cada grupo\n",
        "dict_num = {\n",
        "    'garage':['GarageYrBlt','GarageCars','GarageArea'],\n",
        "    'bsmt':['BsmtFullBath','BsmtHalfBath','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF'],\n",
        "    'extras':['WoodDeckSF','OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch','PoolArea','MiscVal','Fireplaces'],\n",
        "    'local':[],\n",
        "    'infra':['YearBuilt', 'YearRemodAdd', 'LowQualFinSF'],\n",
        "    'terreno_estilo':['MasVnrArea', '1stFlrSF','2ndFlrSF','GrLivArea','LotFrontage','LotArea'],\n",
        "    'bathroom':['FullBath','HalfBath'],\n",
        "    'bedroom':['TotRmsAbvGrd', 'BedroomAbvGr'],\n",
        "    'kitchen':['KitchenAbvGr'],\n",
        "    'roof':[],\n",
        "    'avgs': ['AvgAbvGrLivArea', 'AvgRmsAbvGrdSize', 'AvgBedroomAbvGrSize']\n",
        "}\n",
        "\n",
        "#Descrição de todas as features categóricas em cada grupo\n",
        "dict_cat = {\n",
        "    'garage':['GarageType'],\n",
        "    'bsmt':[],\n",
        "    'extras':['MiscFeature'],\n",
        "    'local':['MSZoning','Neighborhood','Condition1','Condition2'],\n",
        "    'infra':['Foundation','Heating','Electrical'],\n",
        "    'terreno_estilo':['MSSubClass','BldgType','HouseStyle','Exterior1st','Exterior2nd','MasVnrType','LotConfig'],\n",
        "    'bathroom':[],\n",
        "    'bedroom':[],\n",
        "    'kitchen':[],\n",
        "    'roof':['RoofMatl', 'RoofStyle'],\n",
        "    'avgs':[]\n",
        "}\n",
        "\n",
        "#Descrição de todas as features ordinais em cada grupo\n",
        "dict_ord = {\n",
        "    'garage':['GarageFinish','GarageQual','GarageCond','PavedDrive'],\n",
        "    'bsmt':['BsmtExposure','BsmtFinType1','BsmtFinType2','BsmtQual','BsmtCond'],\n",
        "    'extras':['PoolQC','Fence','FireplaceQu'],\n",
        "    'local':['Street','Alley'],\n",
        "    'infra':['Functional','Utilities' ,'OverallQual','OverallCond','ExterQual' ,'ExterCond','HeatingQC','CentralAir'],\n",
        "    'terreno_estilo':['LotShape','LandContour','LandSlope'],\n",
        "    'bathroom':[],\n",
        "    'bedroom':[],\n",
        "    'kitchen':['KitchenQual'],\n",
        "    'roof':[],\n",
        "    'avgs':[]\n",
        "}\n",
        "\n",
        "#Descrição da ordem que deve ser seguida nas features ordinais de cada grupo\n",
        "dict_ordem = {\n",
        "    'garage':[['NA','Unf','RFn','Fin'],['NA','Po','Fa','TA','Gd','Ex'],['NA','Po','Fa','TA','Gd','Ex'],['N','P','Y']],\n",
        "    'bsmt':[\n",
        "              ['NA','No','Mn','Av','Gd'],['NA','Unf','LwQ','Rec','BLQ','ALQ','GLQ'],\n",
        "              ['NA','Unf','LwQ','Rec','BLQ','ALQ','GLQ'],\n",
        "              ['NA','Po','Fa','TA','Gd','Ex'],['NA','Po','Fa','TA','Gd','Ex']\n",
        "           ],\n",
        "    'extras':[['NA','Fa','TA','Gd','Ex'],['NA','MnWw','GdWo','MnPrv','GdPrv'],['NA','Po','Fa','TA','Gd','Ex']],\n",
        "    'local':[['Grvl','Pave'],['NA','Grvl','Pave']],\n",
        "    'infra':[     \n",
        "              ['Typ','Min1','Min2','Mod','Maj1','Maj2','Sev','Sal'],['ELO','NoSeWa','NoSewr','AllPub'],\n",
        "              ['1','2','3','4','5','6','7','8','9','10'],['1','2','3','4','5','6','7','8','9','10'],\n",
        "              ['Po','Fa','TA','Gd','Ex'],['Po','Fa','TA','Gd','Ex'],['Po','Fa','TA','Gd','Ex'],['N','Y']\n",
        "            ],\n",
        "    'terreno_estilo':[['Reg','IR1','IR2','IR3'],['Low','HLS','Bnk','Lvl'],['Gtl','Mod','Sev']],\n",
        "    'bathroom':[],\n",
        "    'bedroom':[],\n",
        "    'kitchen':[['Po','Fa','TA','Gd','Ex']],\n",
        "    'roof': [],\n",
        "    'avgs':[]    \n",
        "}"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFk4ZZhPLo9q"
      },
      "source": [
        "###Como forma escolhida de escolha do número de clusters por agrupamento, nota-se que a entropia é mantida constante pelas transformações, assim, de modo a capturar uma noção simples de conservação da informação do dataset original, limita-se o número total de features (k_total = 80) e escolhem-se a limitação (pois o processo escolhe o melhor baseado na métrica de Silhouette Score) na quantidade de clusters KMeans (k_grupo) baseando-se na proporção da entropia total (H_total) mantida pelos agrupamentos individuais (H_grupo).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OlcOxgXOHYy"
      },
      "source": [
        "#Drop das variáveis não utilizadas\n",
        "X_train.drop(drop,axis=1,inplace=True)\n",
        "X_test.drop(drop,axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oK6v_PkeN1ZJ"
      },
      "source": [
        "import scipy.stats\n",
        "\n",
        "def entropia(data):\n",
        "    p_data = data.value_counts()           \n",
        "    entropy = scipy.stats.entropy(p_data) \n",
        "    return entropy"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3qXLb-wN8cM",
        "outputId": "e909eae1-f53a-46de-feb1-9d16191009a9"
      },
      "source": [
        "entropias = []\n",
        "entropia_total = 0\n",
        "for i in range(len(grupos)):\n",
        "  ent_parcial = entropia(X_train[grupos[i]])\n",
        "  entropia_total+=ent_parcial\n",
        "  entropias.append(ent_parcial)\n",
        "\n",
        "proporcoes_por_grupo = np.array(entropias/entropia_total)\n",
        "print(proporcoes_por_grupo)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.16225749 0.16368793 0.         0.04980689 0.15461735 0.16016279\n",
            " 0.03555755 0.06410313 0.02825312 0.01665573 0.16489802]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-pCBHqCRmAj"
      },
      "source": [
        "def cluster_por_entropia(proporcoes_por_grupo,index,k_original):\n",
        "  return np.maximum(np.ceil(proporcoes_por_grupo[index]*k_original).astype('int'),2) #maior entre o numero e 2, pois devemos ter ao menos 2 clusters"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZmE6wobQ_A8"
      },
      "source": [
        "k_original = 80 #originalmente temos 80 features\n",
        "\n",
        "k_maximo_por_grupo = {\n",
        "    'garage':cluster_por_entropia(proporcoes_por_grupo,0,k_original),\n",
        "    'bsmt':cluster_por_entropia(proporcoes_por_grupo,1,k_original),\n",
        "    'extras':cluster_por_entropia(proporcoes_por_grupo,2,k_original),\n",
        "    'local':cluster_por_entropia(proporcoes_por_grupo,3,k_original),\n",
        "    'infra':cluster_por_entropia(proporcoes_por_grupo,4,k_original),\n",
        "    'terreno_estilo':cluster_por_entropia(proporcoes_por_grupo,5,k_original),\n",
        "    'bathroom':cluster_por_entropia(proporcoes_por_grupo,6,k_original),\n",
        "    'bedroom':cluster_por_entropia(proporcoes_por_grupo,7,k_original),\n",
        "    'kitchen':cluster_por_entropia(proporcoes_por_grupo,8,k_original),\n",
        "    'roof':cluster_por_entropia(proporcoes_por_grupo,9,k_original),\n",
        "    'avgs':cluster_por_entropia(proporcoes_por_grupo,10,k_original)\n",
        "    \n",
        "}"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SpA4E_1Skns",
        "outputId": "b13da0b3-2d72-4b0d-d361-49c10ebdf953"
      },
      "source": [
        "k_maximo_por_grupo"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'avgs': 14,\n",
              " 'bathroom': 3,\n",
              " 'bedroom': 6,\n",
              " 'bsmt': 14,\n",
              " 'extras': 2,\n",
              " 'garage': 13,\n",
              " 'infra': 13,\n",
              " 'kitchen': 3,\n",
              " 'local': 4,\n",
              " 'roof': 2,\n",
              " 'terreno_estilo': 13}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJBuq_wxdHkE"
      },
      "source": [
        "#Utilização novamente do 'truque' do array \n",
        "features_novas_train = np.zeros((len(X_train),1))\n",
        "\n",
        "modelos = []\n",
        "melhores_ks = []\n",
        "\n",
        "for i in range(len(grupos)):\n",
        "  features_novas_do_grupo, Modelo , k_melhor_grupo = features_abstraidas_por_grupo_fit_transform(\n",
        "                                                                                  X_train[grupos[i]],\n",
        "                                                                                  dict_num[grupos_nomes[i]],\n",
        "                                                                                  dict_cat[grupos_nomes[i]],\n",
        "                                                                                  dict_ord[grupos_nomes[i]],\n",
        "                                                                                  dict_ordem[grupos_nomes[i]],\n",
        "                                                                                  k_max=k_maximo_por_grupo[grupos_nomes[i]]\n",
        "                                                                                                            )\n",
        "  features_novas_train = np.append(features_novas_train,features_novas_do_grupo,axis=1)\n",
        "  modelos.append(Modelo)\n",
        "  melhores_ks.append(k_melhor_grupo)\n",
        "\n",
        "#deleção da coluna 'boba'\n",
        "features_novas_train = np.delete(features_novas_train, 0, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fib7jnkp2mHp"
      },
      "source": [
        "features_novas_test = np.zeros((len(X_test),1))\n",
        "\n",
        "for i in range(len(grupos)):\n",
        "  features_novas_do_grupo = features_abstraidas_por_grupo_transform(\n",
        "                                                                    X_test[grupos[i]],\n",
        "                                                                    dict_num[grupos_nomes[i]],\n",
        "                                                                    dict_cat[grupos_nomes[i]],\n",
        "                                                                    dict_ord[grupos_nomes[i]],\n",
        "                                                                    dict_ordem[grupos_nomes[i]],\n",
        "                                                                    modelos[i][0],\n",
        "                                                                    modelos[i][1],\n",
        "                                                                    modelos[i][2],\n",
        "                                                                    modelos[i][3]\n",
        "                                                                    )\n",
        "  features_novas_test = np.append(features_novas_test,features_novas_do_grupo,axis=1)\n",
        "features_novas_test = np.delete(features_novas_test, 0, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0tbFo9o1W6K"
      },
      "source": [
        "#Questão 2\n",
        "\n",
        "##a) Aprimore o pipeline desenvolvido em aula para que seja possível comparar mais de uma técnica de modelagem (por exemplo, KNN e Árvore de decisão) usando um mesmo grid-search;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVT1O-Sj1a_y"
      },
      "source": [
        "Importação de módulos que serão necessários"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0KBpNrVCw6a"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEhCOnKb1fO5"
      },
      "source": [
        "Uma maneira encontrada de utilizar vários estimadores seria através do mecanismo de herança dos estimadores do sklearn, junto da implementação dos métodos pedidos. Infelizmente desta forma o pipeline não é facilmente integrado com a noção de tunagem de hiperparâmetros dado um modelo em específico."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuaDKOJsAi6k"
      },
      "source": [
        "from sklearn.base import BaseEstimator\n",
        "class RegSwitcher(BaseEstimator):\n",
        "\n",
        "  def __init__(self, estimator=KNeighborsRegressor()):\n",
        "\n",
        "      self.estimator = estimator\n",
        "\n",
        "\n",
        "  def fit(self, X, y=None, **kwargs):\n",
        "      self.estimator.fit(X, y)\n",
        "      return self\n",
        "\n",
        "\n",
        "  def predict(self, X, y=None):\n",
        "      return self.estimator.predict(X)\n",
        "\n",
        "\n",
        "  def predict_proba(self, X):\n",
        "      return self.estimator.predict_proba(X)\n",
        "\n",
        "\n",
        "  def score(self, X, y):\n",
        "    return self.estimator.score(X, y)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjckkWhC1-fi"
      },
      "source": [
        "Apenas para fins de exploração maior de possibilidades, adiciona-se uma redução de dimensionalidade antes da aplicação do estimador, para facilitar o treino. (escolhidos testes com 95%,90% e 85% da variância explicada pelos principais componentes).\n",
        "\n",
        "Além disso vale a menção de testes com regressores de máquinas de vetor suporte, random forests e regressão linear simples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyJWM0eu-QkJ",
        "outputId": "d58b5cb3-e78f-4cc6-d74f-8e293033b56b"
      },
      "source": [
        "parameters_GSCV = {\n",
        "    'PCA__n_components':[0.95,0.9,0.85],\n",
        "    'model__estimator': [\n",
        "                         SVR(),\n",
        "                         KNeighborsRegressor(),\n",
        "                         DecisionTreeRegressor(),\n",
        "                         RandomForestRegressor(),\n",
        "                         LinearRegression()\n",
        "                         ]\n",
        "}\n",
        "\n",
        "pipe = Pipeline(steps = [\n",
        "                 ('PCA',PCA(svd_solver = 'full')),\n",
        "                 ('model',RegSwitcher()),\n",
        "])\n",
        "\n",
        "Gs = GridSearchCV(\n",
        "    estimator = pipe,\n",
        "    param_grid = parameters_GSCV,\n",
        "    scoring = 'neg_root_mean_squared_error',\n",
        "    cv = 3\n",
        ")\n",
        "\n",
        "Gs.fit(features_novas_train,y_train)\n",
        "#Output deste fora mantido por conta de apresentar informações do modelo final"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('PCA',\n",
              "                                        PCA(copy=True, iterated_power='auto',\n",
              "                                            n_components=None,\n",
              "                                            random_state=None,\n",
              "                                            svd_solver='full', tol=0.0,\n",
              "                                            whiten=False)),\n",
              "                                       ('model',\n",
              "                                        RegSwitcher(estimator=KNeighborsRegressor(algorithm='auto',\n",
              "                                                                                  leaf_size=30,\n",
              "                                                                                  metric='minkowski',\n",
              "                                                                                  metric_params=None,\n",
              "                                                                                  n_jobs=None,\n",
              "                                                                                  n_neighbors=5,\n",
              "                                                                                  p=2,\n",
              "                                                                                  weights='...\n",
              "                                                                    min_impurity_split=None,\n",
              "                                                                    min_samples_leaf=1,\n",
              "                                                                    min_samples_split=2,\n",
              "                                                                    min_weight_fraction_leaf=0.0,\n",
              "                                                                    n_estimators=100,\n",
              "                                                                    n_jobs=None,\n",
              "                                                                    oob_score=False,\n",
              "                                                                    random_state=None,\n",
              "                                                                    verbose=0,\n",
              "                                                                    warm_start=False),\n",
              "                                              LinearRegression(copy_X=True,\n",
              "                                                               fit_intercept=True,\n",
              "                                                               n_jobs=None,\n",
              "                                                               normalize=False)]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='neg_root_mean_squared_error', verbose=0)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYDDpmlXCzxT",
        "outputId": "27805aee-a896-4f84-ecf0-c84b1aab216a"
      },
      "source": [
        "Gs.best_estimator_\n",
        "# 90% da variância explicada é preservada nestes componentes, melhor modelo é o de árvores"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('PCA',\n",
              "                 PCA(copy=True, iterated_power='auto', n_components=0.9,\n",
              "                     random_state=None, svd_solver='full', tol=0.0,\n",
              "                     whiten=False)),\n",
              "                ('model',\n",
              "                 RegSwitcher(estimator=RandomForestRegressor(bootstrap=True,\n",
              "                                                             ccp_alpha=0.0,\n",
              "                                                             criterion='mse',\n",
              "                                                             max_depth=None,\n",
              "                                                             max_features='auto',\n",
              "                                                             max_leaf_nodes=None,\n",
              "                                                             max_samples=None,\n",
              "                                                             min_impurity_decrease=0.0,\n",
              "                                                             min_impurity_split=None,\n",
              "                                                             min_samples_leaf=1,\n",
              "                                                             min_samples_split=2,\n",
              "                                                             min_weight_fraction_leaf=0.0,\n",
              "                                                             n_estimators=100,\n",
              "                                                             n_jobs=None,\n",
              "                                                             oob_score=False,\n",
              "                                                             random_state=None,\n",
              "                                                             verbose=0,\n",
              "                                                             warm_start=False)))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq0BbCMY2vgr"
      },
      "source": [
        "Como pode-se ver logo a seguir, a performance no conjunto de treino é medíocre, um pouco pior que o modelo muito mais simples apresentado em aula, mesmo com todas estas transformações e manipulações de valores. \n",
        "\n",
        "Hipóteses e soluções são propostas logo a seguir"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lbeoQM5DBFB",
        "outputId": "2941ee70-38eb-4c00-a35d-834742ed4e25"
      },
      "source": [
        "-Gs.best_score_"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39235.33611616312"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbNuNodd83XA"
      },
      "source": [
        "##Questão 1\n",
        "\n",
        "###b) Faça uma análise ilustrando a (possível) qualidade das variáveis propostas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ossc-UHQoH0P"
      },
      "source": [
        "Para efetuar uma análise simples, vamos utilizar primeiramente o quesito feature importances do modelo de Random Forest, para isso mostra-se abaixo o acesso a essa característica."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kd7HwBLontu0",
        "outputId": "df20c071-a999-40e1-fab8-bb033b7d65c6"
      },
      "source": [
        "Gs.best_estimator_[1].estimator.feature_importances_"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.61257803, 0.06542848, 0.06848894, 0.03714375, 0.01870512,\n",
              "       0.01840162, 0.02537265, 0.01349098, 0.04218924, 0.01917945,\n",
              "       0.01304475, 0.0145477 , 0.01520771, 0.01136016, 0.02486142])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOmqDGrApWMf"
      },
      "source": [
        "Como pode-se ver uma grande parte da importância das features pode ser resumida na 1a componente da PCA ! \n",
        "Porém precisamos analisar realmente as variáveis novas criadas, portanto temos de treinar um novo modelo. Segue abaixo a criação, treinamento e estimativa da importância das features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EUodsUemoYu",
        "outputId": "400f554c-c93d-44c6-c6a0-e566ed83f522"
      },
      "source": [
        "rf = RandomForestRegressor(random_state=42)\n",
        "rf.fit(features_novas_train, y_train)\n",
        "\n",
        "feat_df = pd.DataFrame(\n",
        "    rf.feature_importances_, columns=['Importancias'])\n",
        "\n",
        "feat_df=feat_df.iloc[:,0]\n",
        "feat_df"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     0.015515\n",
              "1     0.006372\n",
              "2     0.057792\n",
              "3     0.006586\n",
              "4     0.329490\n",
              "5     0.025649\n",
              "6     0.008108\n",
              "7     0.005027\n",
              "8     0.004095\n",
              "9     0.005465\n",
              "10    0.059239\n",
              "11    0.003203\n",
              "12    0.033313\n",
              "13    0.028392\n",
              "14    0.011621\n",
              "15    0.006310\n",
              "16    0.009424\n",
              "17    0.012319\n",
              "18    0.031438\n",
              "19    0.009114\n",
              "20    0.000788\n",
              "21    0.008297\n",
              "22    0.001337\n",
              "23    0.009255\n",
              "24    0.021820\n",
              "25    0.007539\n",
              "26    0.003635\n",
              "27    0.010915\n",
              "28    0.056624\n",
              "29    0.069736\n",
              "30    0.009348\n",
              "31    0.001099\n",
              "32    0.013482\n",
              "33    0.005751\n",
              "34    0.010842\n",
              "35    0.005444\n",
              "36    0.011853\n",
              "37    0.015613\n",
              "38    0.006613\n",
              "39    0.002671\n",
              "40    0.040218\n",
              "41    0.001623\n",
              "42    0.000834\n",
              "43    0.001359\n",
              "44    0.008213\n",
              "45    0.006622\n",
              "Name: Importancias, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "turUGxJ7p4CG"
      },
      "source": [
        "Se formos olhar para o output do treinamento, notamos que as primeiras 13 features são do grupo 'garage', as 4 próximas são do grupo 'bsmt' e assim por diante, organizando esta informação toda num dicionário:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlgP_cXIqJ9T"
      },
      "source": [
        "dict_ks_por_grupo = {\n",
        "    'garage':melhores_ks[0],\n",
        "    'bsmt': melhores_ks[1],\n",
        "    'extras':melhores_ks[2],\n",
        "    'local':melhores_ks[3],\n",
        "    'infra':melhores_ks[4],\n",
        "    'terreno_estilo':melhores_ks[5],\n",
        "    'bathroom':melhores_ks[6],\n",
        "    'bedroom':melhores_ks[7],\n",
        "    'kitchen':melhores_ks[8],\n",
        "    'roof':melhores_ks[9],\n",
        "    'avgs':melhores_ks[10]\n",
        "}"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Wo6Mr21v5qW",
        "outputId": "17af64db-ed49-4a21-ac06-25a5b8de76f7"
      },
      "source": [
        "dict_ks_por_grupo"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'avgs': 2,\n",
              " 'bathroom': 3,\n",
              " 'bedroom': 6,\n",
              " 'bsmt': 4,\n",
              " 'extras': 2,\n",
              " 'garage': 13,\n",
              " 'infra': 5,\n",
              " 'kitchen': 3,\n",
              " 'local': 4,\n",
              " 'roof': 2,\n",
              " 'terreno_estilo': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylEkm82Pwy8I",
        "outputId": "fb730b4e-e0cd-4298-ddef-f4f9d9a89dea"
      },
      "source": [
        "#aparentemente esta feature tem uma importância relativa de cerca de 0,8 %\n",
        "feat_df.iloc[range(len(feat_df)-2,len(feat_df)-1)].sum()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00821336064181432"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5v4dpypxGIy",
        "outputId": "c4efeb1b-2dde-4661-c826-d2b772103d83"
      },
      "source": [
        "#o que torna pior que garage, que não se espera influência assim na prática\n",
        "feat_df.iloc[range(0,melhores_ks[0])].sum()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5598529320994672"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4nWu9d4xTpL"
      },
      "source": [
        "Conclusão: As features novas, sejam as explicativas ou os agrupamentos como um todo, não foram muito úteis ao modelo. \n",
        "\n",
        "A hipótese do porquê seria pelo fato que escolheram-se as features baseando na tentativa de manter a maior parte da entropia original possível, o que pode ser útil muitas vezes, porém deve-se lembrar que temos um objetivo de regressão de preço de casas, que deve-se dar mais importância para variáveis **correlacionadas com este target**, não necessariamente com o objetivo de manter toda a informação do dataset original.\n",
        "\n",
        "Creio que a utilização de mais algumas análises nesta direção possam ser úteis, como a utilização de métricas como, da wikipédia ([https://pt.wikipedia.org/wiki/Entropia_cruzada](https://)): \n",
        "\n",
        "* *Na teoria da informação, a entropia cruzada se refere à diferença entre duas distribuições de probabilidade p (verdadeira) e q (estimada) sobre o mesmo conjunto de eventos. Na prática, a entropia cruzada mede o número médio de bits necessários para identificar um evento , se a codificação utilizada for otimizada para a distribuição de probabilidade estimada q , em vez de otimizada para a distribuição de probabilidade verdadeira p .*\n",
        "\n",
        "Escolhendo os números de clusters de forma que aqueles que possum maior relação (nesta noção de entropia cruzada) com o target recebam valores mais altos seria um horizonte exploratório bom.\n",
        "\n",
        "Outra alternativa (ainda tratando de teoria da informação) seria em uma análise com base na informação mútua entre essas duas variáveis, ou uma abordagem baseada especificamente para a inclusão de variáveis novas em problemas de regressão como AIC e BIC (respectivamente Akaike e Bayes Information Cryterion)\n",
        "\n",
        "Outras formas de análise, mais algorítimicas, com algumas inclusive baseadas em teorias dos jogos, estão expostas logo a seguir:\n",
        "\n",
        "* **LOFO**: \n",
        "###Explicação & github: https://github.com/aerdem4/lofo-importance\n",
        "###Exemplo: https://www.kaggle.com/aerdem4/optiver-lofo-feature-importance\n",
        "\n",
        "* **Null importances**:\n",
        "###Artigo explicando: https://academic.oup.com/bioinformatics/article/26/10/1340/193348\n",
        "###Notebook com exemplo: https://www.kaggle.com/ogrellier/feature-selection-with-null-importances\n",
        "* **Importância por permutação**: \n",
        "###Explicação: https://eli5.readthedocs.io/en/latest/blackbox/permutation_importance.html\n",
        "* **Outros**:\n",
        "###BorutaPy: https://www.kaggle.com/residentmario/automated-feature-selection-with-boruta\n",
        "###BorutaShap: https://github.com/Ekeany/Boruta-Shap\n",
        "###ShapHypetune: https://github.com/cerlymarco/shap-hypetune"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nm8TpoXC_5GQ"
      },
      "source": [
        "#Questão 3\n",
        "##a) Comparar vários modelos candidatos e escolher o melhor;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYhdRi8s5Zf7"
      },
      "source": [
        "Embora não tenham sido muito bons , o pipeline anterior (junto das features novas) nos deu um resultado mediano, que pode com certeza ser melhorado com alguma tunagem dos hiperparâmetros do melhor modelo. Para isso, vamos manter a Pca anterior e escolher a melhor combinação de valores para o modelo de florestas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUD34gH86As9",
        "outputId": "4c570db6-f522-4808-a337-f2bc6e14166e"
      },
      "source": [
        "Gs.best_estimator_[0]"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PCA(copy=True, iterated_power='auto', n_components=0.9, random_state=None,\n",
              "    svd_solver='full', tol=0.0, whiten=False)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JyLGrnzABg8"
      },
      "source": [
        "parametros_floresta = {\n",
        "    'RF__max_depth':[5,10,15],\n",
        "    'RF__max_features':['auto','sqrt','log2'],\n",
        "    'RF__bootstrap':[True,False],\n",
        "    'RF__max_samples':[0.5,0.75,1.0]\n",
        "}\n",
        "\n",
        "pipe_forest = Pipeline(steps = [\n",
        "                        ('PCA',Gs.best_estimator_[0]),\n",
        "                        ('RF',RandomForestRegressor())\n",
        "])\n",
        "\n",
        "GsRF = GridSearchCV(\n",
        "    estimator = pipe_forest,\n",
        "    param_grid = parametros_floresta,\n",
        "    scoring = 'neg_root_mean_squared_error',\n",
        "    cv = 5\n",
        "    ,n_jobs=-1\n",
        ")"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkQBg8C18Msr",
        "outputId": "7fc3a6f9-249a-49f5-c84b-f635f45c1357"
      },
      "source": [
        "GsRF.fit(features_novas_train,y_train)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:354: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('PCA',\n",
              "                                        PCA(copy=True, iterated_power='auto',\n",
              "                                            n_components=0.9, random_state=None,\n",
              "                                            svd_solver='full', tol=0.0,\n",
              "                                            whiten=False)),\n",
              "                                       ('RF',\n",
              "                                        RandomForestRegressor(bootstrap=True,\n",
              "                                                              ccp_alpha=0.0,\n",
              "                                                              criterion='mse',\n",
              "                                                              max_depth=None,\n",
              "                                                              max_features='auto',\n",
              "                                                              max_leaf_nodes=None,\n",
              "                                                              max_samples=None,\n",
              "                                                              min_impurity_d...\n",
              "                                                              oob_score=False,\n",
              "                                                              random_state=None,\n",
              "                                                              verbose=0,\n",
              "                                                              warm_start=False))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'RF__bootstrap': [True, False],\n",
              "                         'RF__max_depth': [5, 10, 15],\n",
              "                         'RF__max_features': ['auto', 'sqrt', 'log2'],\n",
              "                         'RF__max_samples': [0.5, 0.75, 1.0]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='neg_root_mean_squared_error', verbose=0)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3KW0qsrBAD_",
        "outputId": "33ea5b83-de1b-45af-9777-f0960678d965"
      },
      "source": [
        "GsRF.best_estimator_"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('PCA',\n",
              "                 PCA(copy=True, iterated_power='auto', n_components=0.9,\n",
              "                     random_state=None, svd_solver='full', tol=0.0,\n",
              "                     whiten=False)),\n",
              "                ('RF',\n",
              "                 RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
              "                                       criterion='mse', max_depth=15,\n",
              "                                       max_features='auto', max_leaf_nodes=None,\n",
              "                                       max_samples=0.75,\n",
              "                                       min_impurity_decrease=0.0,\n",
              "                                       min_impurity_split=None,\n",
              "                                       min_samples_leaf=1, min_samples_split=2,\n",
              "                                       min_weight_fraction_leaf=0.0,\n",
              "                                       n_estimators=100, n_jobs=None,\n",
              "                                       oob_score=False, random_state=None,\n",
              "                                       verbose=0, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbDEhripDS9e"
      },
      "source": [
        "#Questão 3\n",
        "###b) Gerar os resultados do melhor modelo na base de teste e enviar para o Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RwRBO8p6abr",
        "outputId": "07c677a2-debf-48b7-ecd9-38e0c12dda2d"
      },
      "source": [
        "y_pred_test = GsRF.predict(features_novas_test)\n",
        "\n",
        "#expectativa de erro\n",
        "print(mean_squared_error(y_test,y_pred_test,squared=False))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38344.32080447204\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-8sktReJAiq"
      },
      "source": [
        "id = test['Id'].copy()\n",
        "\n",
        "test.drop(drop,axis=1,inplace=True)\n",
        "\n",
        "total_area = test['LotArea'] + test['1stFlrSF'] + test['2ndFlrSF']\n",
        "test['AvgAbvGrLivArea'] = test['GrLivArea']/total_area\n",
        "test['AvgRmsAbvGrdSize'] = test['TotRmsAbvGrd']/total_area\n",
        "test['AvgBedroomAbvGrSize'] = test['BedroomAbvGr']/total_area\n",
        "\n",
        "features_novas_test = np.zeros((len(test),1))\n",
        "\n",
        "for i in range(len(grupos)):\n",
        "  features_novas_do_grupo_test = features_abstraidas_por_grupo_transform(\n",
        "                                                                    test[grupos[i]],\n",
        "                                                                    dict_num[grupos_nomes[i]],\n",
        "                                                                    dict_cat[grupos_nomes[i]],\n",
        "                                                                    dict_ord[grupos_nomes[i]],\n",
        "                                                                    dict_ordem[grupos_nomes[i]],\n",
        "                                                                    modelos[i][0],\n",
        "                                                                    modelos[i][1],\n",
        "                                                                    modelos[i][2],\n",
        "                                                                    modelos[i][3]\n",
        "                                                                    )\n",
        "  features_novas_test = np.append(features_novas_test,features_novas_do_grupo_test,axis=1)\n",
        "features_novas_test = np.delete(features_novas_test, 0, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObxGUxHoFzyQ"
      },
      "source": [
        "y_preds = GsRF.predict(features_novas_test)\n",
        "submissao = pd.DataFrame({\n",
        "    'Id': id,\n",
        "    'SalePrice': y_preds\n",
        "})\n",
        "\n",
        "submissao.to_csv('sub.csv',columns=['Id','SalePrice'],index=False)\n",
        "#score no Kaggle = 0.19740"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYPt8XNiAVZx"
      },
      "source": [
        "#Questão 4\n",
        "\n",
        "##a) Identificar um possível problema com a métrica de erro usada (RMSE). Justificar com explicações, exemplos e análises;\n",
        "\n",
        "##b) Apontar uma nova métrica que não tenha esse problema. Justificar com explicações, exemplos e análises."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEtB0eWXOlHO"
      },
      "source": [
        "a) Um possível problema com a métrica de RMSE seria o fato de, ao analisar sua formulação matemática, percebe-se que existe (como desajado) a noção de distância euclidiana. \n",
        "\n",
        "Um modelo que minimiza a distância euclideana está, como pode ser mostrado formalmente, aproximando suas previsões de modo a coincidir com a **média** da previsões reais. \n",
        "\n",
        "Isso pode ser desejável em muitas situações, especialmente em casos que a média é muito provável, como em distribuições normais, a mais presente na descrição de dados contínuos.\n",
        "\n",
        "Entretanto, do ponto de vista prático do problema isso pode ser problemático. Imagenemos por exemplo que desejam-se realizar previsões que rendam mais lucro à empresa. Se o modelo acertar mais em casos em que os preços são muito altos, e permitir-se errar mais em casos em que os preços são menores, é capaz de refletir, em um dado cenário de modelo de negócios, em um maior lucro, dado que provavelmente algumas propriedades muito caras podem ter o seu preço reduzido em muitas vezes, atraindo mais clientes para sua compra.\n",
        "\n",
        "Fazendo uma contrapartida, muitas vezes possíveis proprietários que possuem possibilidade de comprar tais casas podem não \"sentir\" muito a diferença se o preço estiver um pouco acima, logo isso pode não ter um efeito tão simples de se prever, e variar de caso a caso.\n",
        "\n",
        "Um outro ponto de crítica da métrica seria a observação de que o erro é não linear, sendo que valores de erros que estão entre 0 e 1 em módulo são largamente ignorados pela métrica em face de erros maiores, o que é bom na maioria dos casos, mas vale ressaltar que isso depende da definição da unidade nesta escala, o que pode ser em dólares, milhares ou milhões de dólares, sendo assim necessário um cuidado extra na definição de unidade."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ll0U9qf1SX5Z"
      },
      "source": [
        "b) Uma métrica que não possui estes mesmo erros seria o erro absoluto média (sigla em inglês MAE). Ao contrário da RMSE, esta forma de conceitualização de erro, quando minimizado, converge para a mediana da distribuição de dados, o que pode ser igual a média em muitos casos (sendo assim ao menos tão útil quanto) porém mais afastada em outros.\n",
        "\n",
        "No exemplo apontado logo acima, quando existem casas mais caras, a mediana é menor que a média, o que implica em um menor foco nas casas mais caras, o que pode ser desejável em casos de clientela composta de ampla maioria de pessoas com menor condição monetária, em que um erro de 10% é qualitativamente diferente de um erro de 10% para alguém com melhor condição financeira."
      ]
    }
  ]
}